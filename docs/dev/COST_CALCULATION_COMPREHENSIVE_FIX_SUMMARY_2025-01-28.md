# Comprehensive Cost Calculation Fix - All Bugs Resolved

**Date:** 2025-01-28

## Summary

Complete audit and fix of all cost calculation logic in the codebase to properly handle mixed local/cloud model configurations. Found and fixed **3 critical bugs** across metadata display and API calls.

## Bugs Found and Fixed

### Bug #1: Metadata Display Shows "Free (local)" for Mixed Configurations ‚úÖ FIXED

**File:** `src/services/metadataService.ts` (lines 119-147)

**Problem:** Checking only main `provider` field, not separate parser/analysis providers.

**Impact:** When parser uses cloud + analysis uses local (or vice versa), showed "Free (local)" despite actual costs.

**Fix:** Check BOTH `parsingProvider` and `analysisProvider`:
```typescript
const parsingProvider = message.tokenUsage.parsingProvider || message.tokenUsage.provider;
const analysisProvider = message.tokenUsage.analysisProvider || message.tokenUsage.provider;
const bothLocal = parsingProvider === "ollama" && analysisProvider === "ollama";

if (bothLocal) {
    // Show "Free (local)"
} else {
    // Show actual cost
}
```

---

### Bug #2: Anthropic API Calls Using Wrong Provider ‚úÖ FIXED

**File:** `src/services/aiService.ts` (2 locations, both streaming and non-streaming)

**Problem:** Using `settings.aiProvider` instead of local `provider` variable.

**Impact:** Cost calculated for wrong provider:
- If `settings.aiProvider` = "openai" but using Anthropic for analysis
- Cost calculated using OpenAI pricing instead of Anthropic pricing
- Result: Incorrect cost estimates

**Locations:**
- Lines 2468-2493: Anthropic streaming
- Lines 2548-2573: Anthropic non-streaming

**Fix:**
```typescript
// BEFORE (WRONG)
estimatedCost: this.calculateCost(..., settings.aiProvider, ...),
provider: settings.aiProvider,

// AFTER (CORRECT) 
estimatedCost: this.calculateCost(..., provider, ...),
provider: provider,
```

Also added missing `analysisModel`, `analysisProvider`, `analysisTokens`, `analysisCost` tracking fields.

---

### Bug #3: Ollama Missing Analysis Model Tracking ‚úÖ FIXED

**File:** `src/services/aiService.ts` (2 locations, both streaming and non-streaming)

**Problem:** Missing analysis model tracking fields in TokenUsage object.

**Impact:** Metadata display couldn't properly show model information for Ollama.

**Locations:**
- Lines 2675-2688: Ollama streaming
- Lines 2772-2785: Ollama non-streaming

**Fix:** Added missing fields:
```typescript
const tokenUsage: TokenUsage = {
    // ... existing fields ...
    // Track analysis model separately
    analysisModel: model,
    analysisProvider: "ollama",
    analysisTokens: promptTokens + completionTokens,
    analysisCost: 0, // Ollama is local, no cost
};
```

---

### Verification: Query Parser Service Already Correct ‚úÖ

**File:** `src/services/aiQueryParserService.ts`

All API calls (OpenAI, Anthropic, Ollama) already correctly:
- Get provider from `getProviderForPurpose(settings, "parsing")`
- Use local `provider` variable for `calculateCost()`
- Include `parsingModel`, `parsingProvider`, `parsingTokens`, `parsingCost` tracking

**No changes needed!**

---

## Cost Calculation Architecture

### The calculateCost() Function

Both `aiService.ts` and `aiQueryParserService.ts` have identical `calculateCost()` signatures:

```typescript
private static calculateCost(
    promptTokens: number,
    completionTokens: number,
    model: string,
    provider: "openai" | "anthropic" | "openrouter" | "ollama",  // üëà Provider-specific
    cachedPricing: Record<string, { input: number; output: number }>,
): number
```

**Key points:**
1. Takes `provider` parameter (not global setting)
2. Returns 0 for Ollama (local, free)
3. Uses provider-specific pricing from cache
4. Falls back to gpt-4o-mini pricing if model unknown

### Token Usage Flow

**Parsing (Query Parser):**
```
parseWithAI() 
‚Üí callAI() gets provider from "parsing" purpose
‚Üí calls OpenAI/Anthropic/Ollama with correct provider
‚Üí calculateCost() uses correct provider
‚Üí returns TokenUsage with parsingModel, parsingProvider, parsingCost
```

**Analysis (AI Service):**
```
sendMessage()
‚Üí callAI() gets provider from "analysis" purpose  
‚Üí calls OpenAI/Anthropic/Ollama with correct provider
‚Üí calculateCost() uses correct provider
‚Üí returns TokenUsage with analysisModel, analysisProvider, analysisCost
```

**Combined (Task Chat):**
```
Parser TokenUsage + Analysis TokenUsage
‚Üí estimatedCost = parsingCost + analysisCost
‚Üí totalTokens = parsingTokens + analysisTokens
‚Üí Both provider fields tracked separately
```

---

## Test Matrix

| Parser | Analysis | Display | Cost Calculation | Status |
|--------|----------|---------|------------------|--------|
| Ollama | Ollama | "Free (local)" ‚úÖ | $0.00 ‚úÖ | CORRECT |
| OpenAI | Ollama | Show cost ‚úÖ | Parser only ‚úÖ | FIXED |
| Ollama | OpenAI | Show cost ‚úÖ | Analysis only ‚úÖ | FIXED |
| OpenAI | Anthropic | Show cost ‚úÖ | Both ‚úÖ | FIXED |
| Anthropic | Ollama | Show cost ‚úÖ | Parser only ‚úÖ | FIXED |
| Anthropic | OpenAI | Show cost ‚úÖ | Both ‚úÖ | FIXED |

---

## Files Modified

### Main Fixes
1. **src/services/metadataService.ts** (lines 119-147)
   - Fixed display logic to check both parser and analysis providers
   
2. **src/services/aiService.ts** (4 locations)
   - Lines 2468-2493: Fixed Anthropic streaming to use correct provider
   - Lines 2548-2573: Fixed Anthropic non-streaming to use correct provider
   - Lines 2675-2688: Added analysis tracking to Ollama streaming
   - Lines 2772-2785: Added analysis tracking to Ollama non-streaming

### Documentation
3. **docs/dev/COST_CALCULATION_FIX_MIXED_MODELS_2025-01-28.md**
   - Complete analysis of all bugs
   
4. **docs/dev/COST_CALCULATION_COMPREHENSIVE_FIX_SUMMARY_2025-01-28.md** (this file)
   - Summary of all fixes

---

## Impact

### Before Fixes
- ‚ùå Mixed configs showed "Free (local)" incorrectly
- ‚ùå Anthropic costs calculated using wrong provider pricing
- ‚ùå Ollama missing model tracking fields
- ‚ùå Users couldn't track costs accurately

### After Fixes
- ‚úÖ Display correctly shows "Free" only when both parser and analysis are local
- ‚úÖ All API calls use correct provider for cost calculation
- ‚úÖ All providers have complete model tracking
- ‚úÖ Users can accurately track costs in all configurations

---

## Key Principle Established

**ALWAYS use the provider from `getProviderForPurpose()`, never from global settings:**

```typescript
// ‚úÖ CORRECT
const { provider, model } = getProviderForPurpose(settings, "parsing" | "analysis");
// Use local `provider` variable everywhere

// ‚ùå WRONG  
const provider = settings.aiProvider;
// This is the global default, may not match actual provider used
```

---

## Build Status

‚úÖ All TypeScript compilation successful
‚úÖ No runtime errors expected
‚úÖ Backward compatible (existing behavior unchanged for default configs)

---

## Testing Recommendations

1. **Test mixed configurations:**
   - Parser: OpenAI gpt-4o-mini, Analysis: Ollama qwen3:14b
   - Verify metadata shows cost, not "Free (local)"
   
2. **Test cost accuracy:**
   - Compare estimated cost with expected based on pricing
   - Verify parser and analysis costs calculated separately
   
3. **Test provider switching:**
   - Change parser provider in settings
   - Change analysis provider in settings
   - Verify costs update correctly

4. **Test all-local:**
   - Both parser and analysis use Ollama
   - Verify shows "Free (local)"

---

## Status

‚úÖ **COMPLETE** - All bugs fixed, comprehensive audit done, system now respects actual provider configuration everywhere!
