# Ollama JSON Output Fix - 2025-01-24

## Problem

User testing `gpt-oss:20b` model via Ollama discovered critical JSON parsing failures in Task Chat mode:

### **Symptoms**
1. **JSON Parsing Error:**
   ```
   Query parsing error: SyntaxError: Unexpected token '#', "## 1. Âè•Ê≥ïËß£Êûê"... is not valid JSON
   ```

2. **Model returned linguistic analysis instead of JSON:**
   ```markdown
   ## 1. Âè•Ê≥ïËß£ÊûêÔºàÊ†ëÁä∂ÂõæÔºâ
   [Question]
    ‚îú‚îÄ [Wh‚Äëphrase]  Â¶Ç‰Ωï   (adverbial "how")
    ‚îî‚îÄ [VP]
         ‚îú‚îÄ [V]   ÂºÄÂèë     (verb "to develop")
         ‚îî‚îÄ [NP]  Task Chat (direct object, proper‚Äënoun phrase)
   ```

3. **Simple Search keywords appearing in Task Chat mode** (caused by fallback)

4. **Only 1 task returned** (fallback treated entire query as single keyword)

### **Root Cause**

Small open-source models like `gpt-oss:20b` (20B parameters) often:
- Don't reliably follow structured output instructions
- Return explanatory text, analysis, or markdown instead of JSON
- Lack the instruction-following capabilities of larger models (70B+) or commercial models (GPT-4, Claude)

The model interpreted the query as a request for linguistic analysis rather than JSON parsing.

---

## Solution Implemented

### **1. Stronger JSON Output Enforcement in Prompt**

**Added prominent final instruction** at end of system prompt:

```typescript
üö®üö®üö® CRITICAL FINAL INSTRUCTION üö®üö®üö®
YOU MUST RETURN **ONLY** VALID JSON. NO EXPLANATIONS. NO MARKDOWN. NO ANALYSIS.

‚ùå DO NOT return:
- Markdown headings (##, ###)
- Explanatory text before or after JSON
- Dependency trees, syntax analysis, or linguistic breakdowns
- Any text that is not parseable JSON

‚úÖ CORRECT output format:
{
  "coreKeywords": ["keyword1", "keyword2"],
  "keywords": ["expanded1", "expanded2", ...],
  "priority": null,
  "dueDate": null,
  "status": null,
  "folder": null,
  "tags": []
}

‚ö†Ô∏è If you return ANYTHING other than pure JSON, the system will FAIL.
‚ö†Ô∏è Start your response with { and end with }
‚ö†Ô∏è NO markdown code blocks (no ```json), just raw JSON
```

**Reinforced in user message:**
```typescript
content: `Parse this query: "${query}"

CRITICAL: Return ONLY valid JSON. No markdown, no explanations, no code blocks. Start with { and end with }.`
```

### **2. Ollama JSON Format Enforcement**

**Added `format: "json"` parameter** to Ollama API calls:

```typescript
const requestBody: any = {
    model: providerConfig.model,
    messages: messages,
    stream: false,
    options: {
        temperature: 0.1, // Low temperature for consistent parsing
    },
};

// Force JSON output format for Ollama
// This tells Ollama to constrain the model to output valid JSON
requestBody.format = "json";
```

**How Ollama's JSON format works:**
- Constrains the model's output to valid JSON structure
- Works at the sampling level (not just prompting)
- Supported by most recent Ollama models
- More reliable than prompt-only enforcement

### **3. Enhanced Error Detection and Logging**

**Added markdown heading detection:**

```typescript
// Step 1.5: Check if response contains markdown headings (## or ###)
if (cleaned.match(/^#{1,6}\s+/m)) {
    Logger.warn(
        "AI returned markdown analysis instead of JSON. First 200 chars:",
        cleaned.substring(0, 200),
    );
    Logger.warn(
        "This often happens with smaller open-source models. Consider using a larger model or a cloud provider.",
    );
}
```

**Added detailed error logging when no JSON found:**

```typescript
Logger.error("Failed to extract any JSON from AI response. Full response length:", response.length);
Logger.error("Response preview:", response.substring(0, 500));
Logger.error("This model may not support structured JSON output reliably. Consider:");
Logger.error("1. Using a larger model (e.g., llama3.1:70b instead of 20b)");
Logger.error("2. Using a cloud provider (OpenAI, Anthropic) for better reliability");
Logger.error("3. Switching to Simple Search mode (which doesn't require AI parsing)");
```

---

## Impact

### **For gpt-oss:20b and Similar Models**

Before:
```
‚ùå Returns markdown analysis
‚ùå JSON parsing fails 100%
‚ùå Falls back to Simple Search mode
‚ùå Only 1 task found (exact match only)
‚ùå No semantic expansion
```

After:
```
‚úÖ Ollama constrains output to JSON format
‚úÖ JSON parsing should succeed (model-dependent)
‚úÖ Task Chat mode works properly
‚úÖ Multiple tasks returned
‚úÖ Semantic expansion enabled
```

### **Model Recommendations**

**For Ollama Users:**

| Model Size | Reliability | Recommendation |
|-----------|-------------|----------------|
| 7-20B (gpt-oss, mistral, qwen) | ‚ö†Ô∏è Moderate | Try with new fix, may still have issues |
| 30-40B (deepseek-r1:32b) | ‚úÖ Good | Should work reliably |
| 70B+ (llama3.1:70b, qwen:72b) | ‚úÖ Excellent | Highly recommended |

**Cloud Providers (always reliable):**
- ‚úÖ OpenAI (GPT-4o, GPT-4o-mini)
- ‚úÖ Anthropic (Claude 3.5 Sonnet, Claude 3.5 Haiku)
- ‚úÖ OpenRouter (access to many models)

### **When JSON Format Still Fails**

If a model still returns non-JSON despite these fixes:

**Workaround 1: Switch to Simple Search Mode**
- No AI parsing required
- Direct keyword matching
- Faster and more predictable
- Works with any query language

**Workaround 2: Use a Larger Model**
- `llama3.1:70b` instead of `llama3.1:8b`
- `qwen3:72b` instead of `qwen3:14b`
- Better instruction following

**Workaround 3: Use Cloud Provider**
- GPT-4o-mini is very affordable ($0.15 per 1M tokens)
- Claude 3.5 Haiku is also cost-effective
- 100% reliable JSON output

---

## Testing Recommendations

**Test Query:** "Â¶Ç‰ΩïÂºÄÂèë Task Chat s:open"

**Expected Flow:**
1. AI receives prompt with strong JSON enforcement
2. Ollama constrains output with `format: "json"`
3. Model returns valid JSON:
   ```json
   {
     "coreKeywords": ["ÂºÄÂèë", "Task", "Chat"],
     "keywords": ["ÂºÄÂèë", "develop", "build", ...],
     "status": "open"
   }
   ```
4. JSON parsing succeeds
5. Keywords expanded across languages
6. Multiple tasks found and scored
7. AI analyzes and recommends tasks

**If Still Failing:**
- Check console for error logs
- Look for "AI returned markdown analysis" warning
- Review model capabilities
- Consider switching model or provider

---

## Files Modified

### **aiQueryParserService.ts**

1. **Lines 1440-1474**: Added stronger JSON output enforcement
   - Prominent final instruction in system prompt
   - Explicit examples of what NOT to return
   - Clear format specification
   - User message reinforcement

2. **Lines 139-150**: Added markdown heading detection
   - Early warning if model returns analysis
   - Helpful suggestion to use larger model

3. **Lines 229-249**: Enhanced error logging
   - Detailed diagnostics when JSON extraction fails
   - Actionable recommendations for users
   - Preview of failed response

4. **Lines 1912-1949**: Added Ollama JSON format enforcement
   - `format: "json"` parameter
   - Temperature setting (0.1 for consistency)
   - Comprehensive comments explaining behavior

---

## Additional Notes

### **Why "format: json" is Critical for Ollama**

Ollama's `format` parameter works differently than OpenAI's `response_format`:

**Ollama (Constrained Sampling):**
- Modifies token sampling during generation
- Prevents non-JSON tokens from being selected
- Works at runtime, not just training
- More effective than prompting alone

**OpenAI (Structured Outputs):**
- Uses schema validation
- Can specify exact JSON structure
- Enterprise-grade reliability
- Costs slightly more tokens

### **Temperature Setting**

Set to `0.1` (very low) for query parsing because:
- Need deterministic, consistent parsing
- Don't want creative interpretation
- Want same query to parse same way every time
- Lower temperature = more predictable output

### **Future Improvements**

If issues persist with certain models:

1. **Model-Specific Prompts:**
   - Different prompts for different model families
   - Gemma might need different style than LLaMA

2. **JSON Schema Validation:**
   - Define exact schema for Ollama
   - Use stricter format constraints

3. **Multi-Attempt Parsing:**
   - Retry with stronger prompt if first attempt fails
   - Add reprompting logic

4. **Model Capability Detection:**
   - Test model capabilities at startup
   - Warn users if model likely to fail
   - Auto-suggest compatible models

---

## Status

‚úÖ **COMPLETE** - Three-layer fix implemented:
1. Stronger prompting (instruction-level)
2. Format enforcement (API-level)
3. Better error detection (diagnostic-level)

Should dramatically improve JSON output reliability for Ollama models, especially mid-size models (20B-40B parameters).

---

## User Guidance

**If you're using Ollama:**

1. **Update to latest Ollama version** (format parameter support)
2. **Try the same query again** - should work better now
3. **If still failing:**
   - Check console logs for specific error
   - Try a larger model (70B+)
   - Consider cloud provider for critical workflows
   - Use Simple Search mode as fallback

**Console Warnings to Watch For:**

- ‚úÖ Normal: "AI query parser raw response:", "AI query parser parsed:"
- ‚ö†Ô∏è Warning: "AI returned markdown analysis instead of JSON"
- ‚ùå Error: "Failed to extract any JSON from AI response"

If you see the error message, the model is not suitable for Task Chat mode. Switch to Simple Search or use a different model.
